{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xb3fI2c9QMow"
      },
      "source": [
        "### Drive mount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWduGn90z9_A",
        "outputId": "d86e762c-8105-4226-dbcb-052a4a12c6fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2_2R8qU0DO8",
        "outputId": "72491d00-fd55-41e9-c4ca-85e390f08e08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1PHYG04I0Rq1HPcXLG6rnTDHoHEepF_XK/AP/TP2\n",
            " 0.png\t 7.png\t\t\t\t demos\t\t        main.py\n",
            " 1.png\t 8.png\t\t\t\t DLproject2.ipynb       __pycache__\n",
            " 2.png\t 9.png\t\t\t\t gamedemo.ipynb         smol_snek.ipynb\n",
            " 3.png\t agent_play.mp4\t\t\t game_demo.py\t        snake_game.py\n",
            " 4.png\t agent.py\t\t\t'Kopia BaseDL2.ipynb'   weights\n",
            " 5.png\t BaseDL2.ipynb\t\t\t ludwig.py\n",
            " 6.png\t'CoÃÅpia de Kopia BaseDL2.ipynb'\t MainColab1.ipynb\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/AP/TP2\n",
        "\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78liGLuQQKFN"
      },
      "source": [
        "### Game"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqUDeI3w0ElP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy.random import randint\n",
        "\n",
        "\n",
        "class SnakeGame:\n",
        "    \"Implements the snake game core\"\n",
        "\n",
        "    def __init__(\n",
        "        self, width, height, food_amount=1, border=0, grass_growth=0, max_grass=0\n",
        "    ):\n",
        "        \"Initialize board\"\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.board = np.zeros((height, width, 3), dtype=np.float32)\n",
        "        self.food_amount = food_amount\n",
        "        self.border = border\n",
        "        self.grass_growth = grass_growth\n",
        "        self.grass = np.zeros((height, width)) + max_grass\n",
        "        self.max_grass = max_grass\n",
        "        self.reset()\n",
        "\n",
        "    def create_apples(self):\n",
        "        \"create a new apple away from the snake\"\n",
        "        while len(self.apples) < self.food_amount:\n",
        "            apple = (randint(0, self.height - 1), randint(0, self.width - 1))\n",
        "            while apple in self.snake:\n",
        "                apple = (randint(0, self.height - 1), randint(0, self.width - 1))\n",
        "            self.apples.append(apple)\n",
        "\n",
        "    def create_snake(self):\n",
        "        \"create a snake, size 3, at random position and orientation\"\n",
        "        x = randint(5, self.width - 5)  # not t0o close to border\n",
        "        y = randint(5, self.height - 5)\n",
        "        self.direction = randint(0, 4)\n",
        "        self.snake = []\n",
        "        for i in range(5):\n",
        "            if self.direction == 0:\n",
        "                y = y + 1\n",
        "            elif self.direction == 1:\n",
        "                x = x - 1\n",
        "            elif self.direction == 2:\n",
        "                y = y - 1\n",
        "            elif self.direction == 3:\n",
        "                x = x + 1\n",
        "            self.snake.append((y, x))\n",
        "\n",
        "    def grow_snake(self, d):\n",
        "        \"add one position to snake head (0=up, 1=right, 2=down, 3=left)\"\n",
        "        y, x = self.snake[0]\n",
        "        if d == 0:\n",
        "            y = y - 1\n",
        "        elif d == 1:\n",
        "            x = x + 1\n",
        "        elif d == 2:\n",
        "            y = y + 1\n",
        "        else:\n",
        "            x = x - 1\n",
        "        self.snake.insert(0, (y, x))\n",
        "\n",
        "    def check_collisions(self):\n",
        "        \"check if game is over by colliding with edge or itself\"\n",
        "        # just need to check snake's head\n",
        "        x, y = self.snake[0]\n",
        "        if (\n",
        "            x == -1\n",
        "            or x == self.height\n",
        "            or y == -1\n",
        "            or y == self.width\n",
        "            or (x, y) in self.snake[1:]\n",
        "        ):\n",
        "            self.done = True\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"\n",
        "        move snake/game one step\n",
        "        action can be -1 (turn left), 0 (continue), 1 (turn rignt)\n",
        "        \"\"\"\n",
        "        direction = int(action)\n",
        "        assert -1 <= direction <= 1\n",
        "        self.direction += direction\n",
        "        if self.direction < 0:\n",
        "            self.direction = 3\n",
        "        elif self.direction > 3:\n",
        "            self.direction = 0\n",
        "        self.grow_snake(self.direction)  # two steps: grow+remove last\n",
        "        if self.snake[0] in self.apples:\n",
        "            self.apples.remove(self.snake[0])\n",
        "            reward = 1\n",
        "            self.create_apples()  # new apple\n",
        "        else:\n",
        "            self.snake.pop()\n",
        "            self.check_collisions()\n",
        "            if self.done:\n",
        "                reward = -1\n",
        "            else:\n",
        "                reward = 0\n",
        "        if reward >= 0:\n",
        "            x, y = self.snake[0]\n",
        "            reward += self.grass[x, y]\n",
        "            self.grass[x, y] = 0\n",
        "            self.score += reward\n",
        "            self.grass += self.grass_growth\n",
        "            self.grass[self.grass > self.max_grass] = self.max_grass\n",
        "\n",
        "        return self.board_state(), reward, self.done, {\"score\": self.score}\n",
        "\n",
        "    def get_state(self):\n",
        "        \"easily get current state (score, apple, snake head and tail)\"\n",
        "        score = self.score\n",
        "        apple = self.apples\n",
        "        head = self.snake[0]\n",
        "        tail = self.snake[1:]\n",
        "        return score, apple, head, tail, self.direction\n",
        "\n",
        "    def print_state(self):\n",
        "        \"print the current board state\"\n",
        "        for i in range(self.height):\n",
        "            line = \".\" * self.width\n",
        "            for x, y in self.apples:\n",
        "                if y == i:\n",
        "                    line = line[:x] + \"A\" + line[x + 1 :]\n",
        "            for s in self.snake:\n",
        "                x, y = s\n",
        "                if y == i:\n",
        "                    line = line[:x] + \"X\" + line[x + 1 :]\n",
        "            print(line)\n",
        "\n",
        "    def test_step(self, direction):\n",
        "        \"to test: move the snake and print the game state\"\n",
        "        self.step(direction)\n",
        "        self.print_state()\n",
        "        if self.done:\n",
        "            print(\"Game over! Score=\", self.score)\n",
        "\n",
        "    def reset(self):\n",
        "        \"reset state\"\n",
        "        self.score = 0\n",
        "        self.done = False\n",
        "        self.create_snake()\n",
        "        self.apples = []\n",
        "        self.create_apples()\n",
        "        self.grass[:, :] = self.max_grass\n",
        "\n",
        "        return self.board_state(), 0, self.done, {\"score\": self.score}\n",
        "\n",
        "    def board_state(self, mode=\"human\", close=False):\n",
        "        \"Render the environment\"\n",
        "        self.board[:, :, :] = 0\n",
        "        if self.max_grass > 0:\n",
        "            self.board[:, :, 1] = self.grass / self.max_grass * 0.3\n",
        "        if not self.done:\n",
        "            x, y = self.snake[0]\n",
        "            self.board[x, y, :] = 1\n",
        "        for x, y in self.snake[1:]:\n",
        "            self.board[x, y, 0] = 1\n",
        "        for x, y in self.apples:\n",
        "            self.board[x, y, 1] = 1\n",
        "        if self.border == 0:\n",
        "            return self.board\n",
        "        else:\n",
        "            h, w, _ = self.board.shape\n",
        "            board = np.full(\n",
        "                (h + self.border * 2, w + self.border * 2, 3), 0.5, np.float32\n",
        "            )\n",
        "            board[self.border : -self.border, self.border : -self.border] = self.board\n",
        "            return board\n",
        "\n",
        "\n",
        "# just run this if this file is the main\n",
        "# if __name__ == '__main__':\n",
        "# game = SnakeGame(20,20)\n",
        "# game.print_state()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSZ-wL_8S_pj"
      },
      "source": [
        "### Heuristic agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VefgDl0CTDv5"
      },
      "outputs": [],
      "source": [
        "from math import sqrt\n",
        "from copy import deepcopy\n",
        "\n",
        "\n",
        "class HeuristicAgent:\n",
        "    def __init__(self, env: SnakeGame):\n",
        "        self.env = env\n",
        "        self.possible_actions = [-1, 0, 1]\n",
        "\n",
        "    def generate_examples(self, n: int, force_trunc: bool = False):\n",
        "        \"\"\"\n",
        "        Plays new games according to a heuristic policy until number of example transitions exceeds n.\n",
        "        Setting `force_trunc` to True forces output list to have size = n.\n",
        "        \"\"\"\n",
        "        examples = list()\n",
        "        while len(examples) < n:\n",
        "            transitions = self._play_game()\n",
        "            examples.extend(transitions)\n",
        "            print(f\"Currently there is {len(examples)} examples\")\n",
        "        return examples if not force_trunc else examples[:n]\n",
        "\n",
        "    def _play_game(self):\n",
        "        transitions = list()\n",
        "        board_state, _, done, _ = self.env.reset()\n",
        "        steps = 0\n",
        "        total_reward = 0\n",
        "        while not done:\n",
        "            new_state, reward, done, _, action = self._take_action(\n",
        "                *self.env.get_state()\n",
        "            )\n",
        "            transition = (board_state, action, reward, new_state, done)\n",
        "            transitions.append(transition)\n",
        "            board_state = new_state\n",
        "            steps += 1\n",
        "            total_reward += reward\n",
        "            if steps % 100 == 0:\n",
        "                print(f\"After {steps} steps total reward = {total_reward}\")\n",
        "        return transitions\n",
        "\n",
        "    def _take_action(self, score, apples, head, tail, direction):\n",
        "        closest_apple = min(apples, key=lambda apple: _distance(apple, head))\n",
        "        action_scores = list()\n",
        "        for action in self.possible_actions:\n",
        "            _env = deepcopy(self.env)\n",
        "            _, reward, done, _ = _env.step(action)\n",
        "            if reward == 1:\n",
        "                action_scores.append(0)\n",
        "            elif done:\n",
        "                action_scores.append(self.env.width * self.env.height * 2)\n",
        "            else:\n",
        "                _, _, head, _, _ = _env.get_state()\n",
        "                action_scores.append(_distance(head, closest_apple))\n",
        "        action_index = np.argmin(action_scores)\n",
        "        action = self.possible_actions[action_index]\n",
        "        assert -1 <= action <= 1\n",
        "        return *self.env.step(action), action\n",
        "\n",
        "\n",
        "def _distance(p1: tuple, p2: tuple):\n",
        "    x1, y1 = p1\n",
        "    x2, y2 = p2\n",
        "    return sqrt((x1 - x2) ** 2 + (y1 - y2) ** 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akAoDNddQFPE"
      },
      "source": [
        "### DQN Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbpMWe2WUXuD"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from collections import deque\n",
        "from typing import Iterable, List, Dict, Any\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from copy import deepcopy\n",
        "\n",
        "\n",
        "class DqnAgent:\n",
        "    def __init__(\n",
        "        self,\n",
        "        env: SnakeGame,\n",
        "        action_space: List = [-1, 0, 1],\n",
        "        replay_memory_size: int = 2**16,\n",
        "    ) -> None:\n",
        "        self.env = env\n",
        "        self.action_space = action_space\n",
        "        self.state_shape = self.env.board_state().shape\n",
        "        self.model = self._create_model()\n",
        "        self.target_model = self._create_model()\n",
        "        self.target_model.set_weights(self.model.get_weights())\n",
        "        self.replay_memory = deque(maxlen=replay_memory_size)\n",
        "        self.rewards: List[float] = list()\n",
        "        self.steps_per_episode: List[int] = list()\n",
        "        self.data_to_log: List[Dict[str, Any]] = list()\n",
        "\n",
        "    def _create_model(self):\n",
        "        model = tf.keras.Sequential()\n",
        "\n",
        "        model.add(\n",
        "            tf.keras.layers.Conv2D(\n",
        "                filters=32,\n",
        "                kernel_size=(3, 3),\n",
        "                activation=\"relu\",\n",
        "                padding=\"same\",\n",
        "                kernel_initializer=tf.keras.initializers.HeNormal(),\n",
        "                input_shape=self.env.board_state().shape,\n",
        "            )\n",
        "        )\n",
        "        model.add(tf.keras.layers.BatchNormalization())\n",
        "        model.add(\n",
        "            tf.keras.layers.Conv2D(\n",
        "                filters=128,\n",
        "                kernel_size=(3, 3),\n",
        "                activation=\"relu\",\n",
        "                padding=\"same\",\n",
        "                kernel_initializer=tf.keras.initializers.HeNormal(),\n",
        "            )\n",
        "        )\n",
        "        model.add(tf.keras.layers.BatchNormalization())\n",
        "        model.add(\n",
        "            tf.keras.layers.Conv2D(\n",
        "                filters=64,\n",
        "                kernel_size=(3, 3),\n",
        "                activation=\"relu\",\n",
        "                padding=\"same\",\n",
        "                kernel_initializer=tf.keras.initializers.HeNormal(),\n",
        "            )\n",
        "        )\n",
        "        model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
        "        model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "        model.add(tf.keras.layers.Flatten())\n",
        "        model.add(\n",
        "            tf.keras.layers.Dense(\n",
        "                64,\n",
        "                activation=\"relu\",\n",
        "                kernel_initializer=tf.keras.initializers.HeNormal(),\n",
        "            )\n",
        "        )\n",
        "        model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "        model.add(\n",
        "            tf.keras.layers.Dense(\n",
        "                32,\n",
        "                activation=\"relu\",\n",
        "                kernel_initializer=tf.keras.initializers.HeNormal(),\n",
        "            )\n",
        "        )\n",
        "        model.add(tf.keras.layers.BatchNormalization())\n",
        "        model.add(\n",
        "            tf.keras.layers.Dense(\n",
        "                16,\n",
        "                activation=\"relu\",\n",
        "                kernel_initializer=tf.keras.initializers.HeNormal(),\n",
        "            )\n",
        "        )\n",
        "        model.add(tf.keras.layers.BatchNormalization())\n",
        "        model.add(\n",
        "            tf.keras.layers.Dense(\n",
        "                3,\n",
        "                activation=\"linear\",\n",
        "                kernel_initializer=tf.keras.initializers.RandomUniform(\n",
        "                    minval=-0.03, maxval=0.03\n",
        "                ),\n",
        "            )\n",
        "        )\n",
        "        return model\n",
        "\n",
        "    def _train(self, done: bool, discount_factor: float, batch_size: int, epochs: int):\n",
        "        mini_batch = random.sample(self.replay_memory, batch_size)\n",
        "        current_states = np.array([transition[0] for transition in mini_batch])\n",
        "        action_indices = np.array(\n",
        "            [self._action_index(transition[1]) for transition in mini_batch]\n",
        "        )\n",
        "        rewards = np.array([transition[2] for transition in mini_batch])\n",
        "        future_states = np.array([transition[3] for transition in mini_batch])\n",
        "        not_dones = np.array([int(not transition[4]) for transition in mini_batch])\n",
        "        # assert (0 <= action_indices).all() and (action_indices <= 2).all()\n",
        "        current_qs = self.model.predict(current_states)\n",
        "        # o riginal_qs = deepcopy(current_qs)\n",
        "        future_qs = self.target_model.predict(future_states)\n",
        "        max_future_qs: np.ndarray = (\n",
        "            rewards + discount_factor * np.max(future_qs, axis=1) * not_dones\n",
        "        )\n",
        "        # assert max_future_qs.shape == rewards.shape\n",
        "        current_qs[np.arange(len(current_qs)), action_indices] = max_future_qs\n",
        "        # assert current_qs.shape == (batch_size, 3)\n",
        "        # assert np.isclose(\n",
        "        #     np.all(\n",
        "        #         np.sum(current_qs - original_qs, axis=1)\n",
        "        #         - np.max(current_qs - original_qs, axis=1)\n",
        "        #     ),\n",
        "        #     0,\n",
        "        #     atol=10**-5,\n",
        "        # )\n",
        "\n",
        "        self.model.fit(\n",
        "            current_states, current_qs, batch_size=64, shuffle=True, epochs=epochs\n",
        "        )\n",
        "\n",
        "    def train(\n",
        "        self,\n",
        "        episodes: int,\n",
        "        *,\n",
        "        min_epsilon: float,\n",
        "        max_epsilon: float,\n",
        "        decay: float,\n",
        "        learning_rate: float,\n",
        "        discount_factor: float,\n",
        "        epochs: int = 10,\n",
        "        initial_examples: Iterable = list(),\n",
        "        batch_size: int = 2**10,\n",
        "        min_steps_to_update_target_model: int = 50,\n",
        "        episodes_to_save_log: int = None,\n",
        "        episodes_to_save_model: int = None,\n",
        "    ):\n",
        "        learning_rate = learning_rate\n",
        "        self.model.compile(\n",
        "            loss=\"mse\",\n",
        "            optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "        )\n",
        "        self.replay_memory.extend(initial_examples)\n",
        "        # assert len(self.replay_memory) > 0\n",
        "        step_counter = 0\n",
        "        epsilon = max_epsilon\n",
        "        for episode in range(1, episodes + 1):\n",
        "            total_reward, steps_per_episode = 0, 0\n",
        "            state, _, done, _ = self.env.reset()\n",
        "\n",
        "            while not done:\n",
        "                step_counter += 1\n",
        "                steps_per_episode += 1\n",
        "                action = self._epsilon_greedy_action(epsilon, state)\n",
        "                next_state, reward, done, _ = self.env.step(action)\n",
        "                self.replay_memory.append((state, action, reward, next_state, done))\n",
        "                if step_counter % 4 == 0 or done:\n",
        "                    self._train(done, discount_factor, batch_size, epochs=epochs)\n",
        "\n",
        "                state = next_state\n",
        "                total_reward += reward\n",
        "                if done:\n",
        "                    print(\n",
        "                        f\"##### Episode {episode} reward = {total_reward} steps = {steps_per_episode} #####\"\n",
        "                    )\n",
        "                    self.rewards.append(total_reward)\n",
        "                    self.steps_per_episode.append(step_counter)\n",
        "                    if step_counter >= min_steps_to_update_target_model:\n",
        "                        self.target_model.set_weights(self.model.get_weights())\n",
        "                        step_counter = 0\n",
        "            epsilon = min_epsilon + (max_epsilon - min_epsilon) * np.exp(\n",
        "                -decay * epsilon\n",
        "            )\n",
        "\n",
        "    def _epsilon_greedy_action(self, epsilon, state) -> int:\n",
        "        if np.random.rand() <= epsilon:\n",
        "            action = np.random.choice(self.action_space)\n",
        "        else:\n",
        "            state_reshaped = state.reshape((1, *state.shape))\n",
        "            predicted_q_values = self.model.predict(state_reshaped).flatten()\n",
        "            action = self._choose_action(predicted_q_values)\n",
        "        return action\n",
        "\n",
        "    def play_game(self):\n",
        "        state, _, done, _ = self.env.reset()\n",
        "        self.env.print_state()\n",
        "        total_reward = 0\n",
        "        while not done:\n",
        "            state_reshaped = state.reshape((1, *state.shape))\n",
        "            predicted_q_values = self.model.predict(state_reshaped).flatten()\n",
        "            action = self._choose_action(predicted_q_values)\n",
        "            state, reward, done, _ = self.env.step(action)\n",
        "            total_reward += reward\n",
        "            self.env.print_state()\n",
        "        return total_reward\n",
        "\n",
        "    def _choose_action(self, q_values: np.ndarray) -> int:\n",
        "        action_index = np.argmax(q_values)\n",
        "        action = self.action_space[action_index]\n",
        "        assert -1 <= action <= 1\n",
        "        return action\n",
        "\n",
        "    def _action_index(self, action: int) -> int:\n",
        "        index = self.action_space.index(action)\n",
        "        assert 0 <= index <= 2\n",
        "        return index\n",
        "\n",
        "    def _save_log(self, filename: str = \"training.log\") -> None:\n",
        "        with open(filename, \"a\") as file:\n",
        "            for log in self.data_to_log:\n",
        "                file.write(str(log) + \"\\n\")\n",
        "        episodes = range(1, len(self.rewards) + 1)\n",
        "        plt.plot(episodes, self.rewards)\n",
        "        plt.xlabel(\"Episode\")\n",
        "        plt.ylabel(\"Total Reward\")\n",
        "        plt.title(\"Total Reward per Episode\")\n",
        "        plt.savefig(\"rewards.png\")\n",
        "\n",
        "    def plot_rewards(self):\n",
        "        episodes = range(1, len(self.rewards) + 1)\n",
        "        plt.plot(episodes, self.rewards)\n",
        "        plt.xlabel(\"Episode\")\n",
        "        plt.ylabel(\"Total Reward\")\n",
        "        plt.title(\"Total Reward per Episode\")\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Wpg0yiMQRYr"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xF0GWRjbEJN"
      },
      "source": [
        "#### Create game"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Dt9WG0TXgW_"
      },
      "outputs": [],
      "source": [
        "game = SnakeGame(\n",
        "    width=14, height=14, border=5, food_amount=1, grass_growth=0.001, max_grass=0.05\n",
        ")\n",
        "state_shape = game.board_state().shape\n",
        "action_space = [-1, 0, 1]  # Left,Same, Right"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeTSGBjvbAHu"
      },
      "source": [
        "#### Generate examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oq5qDA5-Xvn3",
        "outputId": "adb17889-ea0b-4ce5-c214-8343844bc5e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After 100 steps total reward = 15.670000000000014\n",
            "Currently there is 165 examples\n",
            "After 100 steps total reward = 16.874000000000027\n",
            "After 200 steps total reward = 28.642000000000092\n",
            "After 300 steps total reward = 39.18999999999998\n",
            "Currently there is 485 examples\n",
            "After 100 steps total reward = 14.60800000000002\n",
            "Currently there is 640 examples\n",
            "After 100 steps total reward = 14.526000000000023\n",
            "After 200 steps total reward = 27.29800000000008\n",
            "After 300 steps total reward = 39.012000000000036\n",
            "Currently there is 1009 examples\n",
            "After 100 steps total reward = 14.312000000000017\n",
            "After 200 steps total reward = 24.966000000000072\n",
            "Currently there is 1209 examples\n",
            "Currently there is 1270 examples\n",
            "After 100 steps total reward = 12.696000000000016\n",
            "Currently there is 1377 examples\n",
            "After 100 steps total reward = 15.55200000000002\n",
            "After 200 steps total reward = 27.950000000000067\n",
            "After 300 steps total reward = 40.631999999999955\n",
            "Currently there is 1730 examples\n",
            "After 100 steps total reward = 17.944000000000027\n",
            "After 200 steps total reward = 31.598000000000088\n",
            "After 300 steps total reward = 44.515999999999856\n",
            "Currently there is 2035 examples\n",
            "After 100 steps total reward = 12.722000000000017\n",
            "Currently there is 2179 examples\n",
            "After 100 steps total reward = 13.628000000000014\n",
            "Currently there is 2348 examples\n",
            "After 100 steps total reward = 15.324000000000009\n",
            "Currently there is 2506 examples\n",
            "After 100 steps total reward = 14.66800000000002\n",
            "After 200 steps total reward = 28.412000000000077\n",
            "Currently there is 2776 examples\n",
            "After 100 steps total reward = 12.724000000000016\n",
            "After 200 steps total reward = 27.32000000000007\n",
            "Currently there is 3047 examples\n",
            "After 100 steps total reward = 19.58000000000002\n",
            "After 200 steps total reward = 31.470000000000084\n",
            "Currently there is 3318 examples\n",
            "After 100 steps total reward = 17.574000000000026\n",
            "After 200 steps total reward = 30.10000000000008\n",
            "Currently there is 3558 examples\n",
            "After 100 steps total reward = 16.58200000000002\n",
            "Currently there is 3736 examples\n",
            "After 100 steps total reward = 15.494000000000021\n",
            "After 200 steps total reward = 30.940000000000072\n",
            "Currently there is 3992 examples\n",
            "After 100 steps total reward = 14.614000000000015\n",
            "After 200 steps total reward = 30.276000000000067\n",
            "Currently there is 4261 examples\n",
            "After 100 steps total reward = 14.580000000000018\n",
            "Currently there is 4428 examples\n",
            "After 100 steps total reward = 15.868000000000018\n",
            "Currently there is 4567 examples\n",
            "After 100 steps total reward = 14.59400000000002\n",
            "After 200 steps total reward = 31.040000000000045\n",
            "Currently there is 4839 examples\n",
            "After 100 steps total reward = 11.770000000000016\n",
            "After 200 steps total reward = 28.578000000000063\n",
            "Currently there is 5047 examples\n",
            "After 100 steps total reward = 14.454000000000029\n",
            "After 200 steps total reward = 29.790000000000095\n",
            "After 300 steps total reward = 42.75999999999986\n",
            "Currently there is 5373 examples\n",
            "After 100 steps total reward = 15.09800000000001\n",
            "After 200 steps total reward = 25.606000000000048\n",
            "Currently there is 5626 examples\n",
            "After 100 steps total reward = 13.404000000000007\n",
            "After 200 steps total reward = 28.246000000000063\n",
            "Currently there is 5877 examples\n",
            "After 100 steps total reward = 14.702000000000025\n",
            "After 200 steps total reward = 30.402000000000065\n",
            "Currently there is 6112 examples\n",
            "After 100 steps total reward = 17.608000000000025\n",
            "Currently there is 6280 examples\n",
            "After 100 steps total reward = 13.566000000000013\n",
            "Currently there is 6426 examples\n",
            "After 100 steps total reward = 16.74800000000002\n",
            "Currently there is 6612 examples\n",
            "After 100 steps total reward = 12.178000000000008\n",
            "Currently there is 6770 examples\n",
            "After 100 steps total reward = 18.542000000000023\n",
            "After 200 steps total reward = 33.256000000000014\n",
            "Currently there is 6997 examples\n",
            "Currently there is 7048 examples\n",
            "After 100 steps total reward = 15.67600000000002\n",
            "After 200 steps total reward = 30.34200000000008\n",
            "Currently there is 7298 examples\n",
            "After 100 steps total reward = 19.54400000000001\n",
            "Currently there is 7417 examples\n",
            "Currently there is 7500 examples\n",
            "Currently there is 7582 examples\n",
            "After 100 steps total reward = 13.842000000000015\n",
            "After 200 steps total reward = 27.62000000000008\n",
            "After 300 steps total reward = 39.433999999999955\n",
            "After 400 steps total reward = 54.37199999999968\n",
            "Currently there is 7989 examples\n",
            "After 100 steps total reward = 15.510000000000023\n",
            "Currently there is 8098 examples\n",
            "After 100 steps total reward = 15.526000000000025\n",
            "After 200 steps total reward = 28.900000000000066\n",
            "Currently there is 8334 examples\n",
            "After 100 steps total reward = 14.622000000000018\n",
            "After 200 steps total reward = 31.396000000000072\n",
            "After 300 steps total reward = 42.04999999999986\n",
            "Currently there is 8638 examples\n",
            "After 100 steps total reward = 16.430000000000017\n",
            "After 200 steps total reward = 29.16200000000008\n",
            "Currently there is 8838 examples\n",
            "After 100 steps total reward = 15.43600000000003\n",
            "Currently there is 8978 examples\n",
            "After 100 steps total reward = 15.504000000000026\n",
            "After 200 steps total reward = 31.118000000000077\n",
            "Currently there is 9186 examples\n",
            "After 100 steps total reward = 16.73800000000002\n",
            "After 200 steps total reward = 31.478000000000065\n",
            "After 300 steps total reward = 49.4579999999998\n",
            "Currently there is 9492 examples\n",
            "After 100 steps total reward = 15.404000000000021\n",
            "After 200 steps total reward = 30.970000000000084\n",
            "Currently there is 9695 examples\n",
            "After 100 steps total reward = 18.74200000000002\n",
            "After 200 steps total reward = 31.470000000000084\n",
            "After 300 steps total reward = 43.305999999999834\n",
            "Currently there is 10058 examples\n",
            "After 100 steps total reward = 14.606000000000021\n",
            "Currently there is 10173 examples\n",
            "After 100 steps total reward = 12.214000000000004\n",
            "After 200 steps total reward = 26.814000000000057\n",
            "After 300 steps total reward = 38.399999999999984\n",
            "Currently there is 10497 examples\n",
            "Currently there is 10579 examples\n",
            "After 100 steps total reward = 14.522000000000013\n",
            "After 200 steps total reward = 26.982000000000063\n",
            "Currently there is 10827 examples\n",
            "After 100 steps total reward = 15.27400000000001\n",
            "After 200 steps total reward = 27.79200000000007\n",
            "After 300 steps total reward = 39.51599999999991\n",
            "After 400 steps total reward = 50.42199999999966\n",
            "Currently there is 11259 examples\n",
            "After 100 steps total reward = 14.65400000000001\n",
            "After 200 steps total reward = 30.124000000000073\n",
            "Currently there is 11550 examples\n",
            "After 100 steps total reward = 17.576000000000025\n",
            "After 200 steps total reward = 34.38000000000006\n",
            "Currently there is 11757 examples\n",
            "Currently there is 11852 examples\n",
            "After 100 steps total reward = 13.596000000000021\n",
            "Currently there is 12038 examples\n",
            "After 100 steps total reward = 15.646000000000027\n",
            "After 200 steps total reward = 30.336000000000077\n",
            "Currently there is 12287 examples\n",
            "After 100 steps total reward = 11.606000000000014\n",
            "After 200 steps total reward = 26.216000000000076\n",
            "Currently there is 12489 examples\n",
            "After 100 steps total reward = 13.55200000000001\n",
            "After 200 steps total reward = 25.856000000000048\n",
            "Currently there is 12760 examples\n",
            "After 100 steps total reward = 14.452000000000009\n",
            "After 200 steps total reward = 29.988000000000046\n",
            "Currently there is 13017 examples\n",
            "After 100 steps total reward = 14.618000000000022\n",
            "Currently there is 13124 examples\n",
            "After 100 steps total reward = 13.556000000000003\n",
            "After 200 steps total reward = 26.31000000000006\n",
            "Currently there is 13418 examples\n",
            "After 100 steps total reward = 14.650000000000018\n",
            "After 200 steps total reward = 26.484000000000083\n",
            "Currently there is 13713 examples\n",
            "After 100 steps total reward = 13.784000000000017\n",
            "Currently there is 13870 examples\n",
            "After 100 steps total reward = 15.466000000000014\n",
            "Currently there is 14064 examples\n",
            "After 100 steps total reward = 15.824000000000021\n",
            "After 200 steps total reward = 28.514000000000078\n",
            "After 300 steps total reward = 42.20599999999992\n",
            "After 400 steps total reward = 56.18399999999964\n",
            "Currently there is 14475 examples\n",
            "After 100 steps total reward = 15.68400000000002\n",
            "After 200 steps total reward = 27.36200000000008\n",
            "Currently there is 14731 examples\n",
            "After 100 steps total reward = 12.708000000000013\n",
            "After 200 steps total reward = 26.272000000000066\n",
            "After 300 steps total reward = 37.771999999999984\n",
            "After 400 steps total reward = 49.53199999999976\n",
            "Currently there is 15161 examples\n",
            "After 100 steps total reward = 16.498000000000026\n",
            "After 200 steps total reward = 28.732000000000074\n",
            "Currently there is 15381 examples\n",
            "After 100 steps total reward = 14.434000000000015\n",
            "After 200 steps total reward = 29.17000000000007\n",
            "Currently there is 15617 examples\n",
            "After 100 steps total reward = 19.500000000000018\n",
            "Currently there is 15723 examples\n",
            "After 100 steps total reward = 16.822000000000017\n",
            "After 200 steps total reward = 30.500000000000075\n",
            "Currently there is 15988 examples\n",
            "After 100 steps total reward = 14.842000000000029\n",
            "After 200 steps total reward = 29.324000000000066\n",
            "After 300 steps total reward = 43.30799999999983\n",
            "Currently there is 16298 examples\n",
            "After 100 steps total reward = 14.71200000000001\n",
            "After 200 steps total reward = 29.292000000000055\n",
            "Currently there is 16502 examples\n",
            "After 100 steps total reward = 17.626000000000023\n",
            "After 200 steps total reward = 31.412000000000074\n",
            "Currently there is 16747 examples\n",
            "After 100 steps total reward = 14.706000000000031\n",
            "Currently there is 16906 examples\n",
            "After 100 steps total reward = 16.50800000000002\n",
            "Currently there is 17024 examples\n",
            "After 100 steps total reward = 16.470000000000017\n",
            "Currently there is 17186 examples\n",
            "After 100 steps total reward = 14.546000000000017\n",
            "Currently there is 17348 examples\n",
            "After 100 steps total reward = 15.694000000000027\n",
            "Currently there is 17453 examples\n",
            "After 100 steps total reward = 15.792000000000026\n",
            "After 200 steps total reward = 31.23200000000007\n",
            "Currently there is 17658 examples\n",
            "After 100 steps total reward = 14.584000000000026\n",
            "After 200 steps total reward = 30.186000000000078\n",
            "Currently there is 17909 examples\n",
            "After 100 steps total reward = 14.692000000000023\n",
            "After 200 steps total reward = 30.39800000000008\n",
            "After 300 steps total reward = 43.09199999999992\n",
            "After 400 steps total reward = 57.01399999999967\n",
            "Currently there is 18387 examples\n",
            "After 100 steps total reward = 16.77400000000003\n",
            "Currently there is 18585 examples\n",
            "After 100 steps total reward = 15.500000000000014\n",
            "Currently there is 18710 examples\n",
            "After 100 steps total reward = 14.710000000000019\n",
            "After 200 steps total reward = 28.95800000000006\n",
            "Currently there is 18983 examples\n",
            "After 100 steps total reward = 15.772000000000029\n",
            "Currently there is 19116 examples\n",
            "After 100 steps total reward = 13.652000000000013\n",
            "After 200 steps total reward = 28.088000000000065\n",
            "Currently there is 19355 examples\n",
            "After 100 steps total reward = 14.330000000000007\n",
            "After 200 steps total reward = 28.914000000000065\n",
            "After 300 steps total reward = 40.58799999999991\n",
            "Currently there is 19720 examples\n",
            "After 100 steps total reward = 14.35600000000002\n",
            "After 200 steps total reward = 26.712000000000085\n",
            "Currently there is 19938 examples\n",
            "After 100 steps total reward = 15.522000000000016\n",
            "Currently there is 20056 examples\n",
            "After 100 steps total reward = 14.284000000000011\n",
            "After 200 steps total reward = 27.862000000000076\n",
            "Currently there is 20344 examples\n",
            "After 100 steps total reward = 14.698000000000013\n",
            "Currently there is 20509 examples\n",
            "After 100 steps total reward = 15.582000000000019\n",
            "After 200 steps total reward = 29.240000000000073\n",
            "After 300 steps total reward = 40.0639999999999\n",
            "Currently there is 20827 examples\n",
            "After 100 steps total reward = 16.59200000000002\n",
            "After 200 steps total reward = 30.280000000000076\n",
            "After 300 steps total reward = 39.56799999999992\n",
            "Currently there is 21207 examples\n",
            "Currently there is 21304 examples\n",
            "After 100 steps total reward = 15.556000000000017\n",
            "Currently there is 21459 examples\n",
            "After 100 steps total reward = 14.780000000000017\n",
            "After 200 steps total reward = 27.56000000000008\n",
            "After 300 steps total reward = 43.31199999999992\n",
            "Currently there is 21767 examples\n",
            "After 100 steps total reward = 11.568000000000007\n",
            "After 200 steps total reward = 25.32000000000007\n",
            "Currently there is 22034 examples\n",
            "After 100 steps total reward = 18.77000000000003\n",
            "After 200 steps total reward = 33.56600000000009\n",
            "Currently there is 22283 examples\n",
            "After 100 steps total reward = 17.748000000000026\n",
            "Currently there is 22409 examples\n",
            "After 100 steps total reward = 15.658000000000024\n",
            "After 200 steps total reward = 33.31800000000003\n",
            "After 300 steps total reward = 45.06399999999981\n",
            "Currently there is 22806 examples\n",
            "After 100 steps total reward = 14.780000000000019\n",
            "After 200 steps total reward = 29.444000000000077\n",
            "Currently there is 23085 examples\n",
            "After 100 steps total reward = 14.274000000000017\n",
            "Currently there is 23261 examples\n",
            "After 100 steps total reward = 13.806000000000017\n",
            "After 200 steps total reward = 28.354000000000074\n",
            "Currently there is 23482 examples\n",
            "After 100 steps total reward = 16.546000000000017\n",
            "Currently there is 23631 examples\n",
            "After 100 steps total reward = 16.69000000000003\n",
            "After 200 steps total reward = 29.344000000000094\n",
            "Currently there is 23895 examples\n",
            "After 100 steps total reward = 15.242000000000022\n",
            "After 200 steps total reward = 28.826000000000075\n",
            "After 300 steps total reward = 41.6459999999999\n",
            "Currently there is 24203 examples\n",
            "After 100 steps total reward = 15.778000000000025\n",
            "After 200 steps total reward = 27.302000000000074\n",
            "After 300 steps total reward = 37.91399999999996\n",
            "Currently there is 24556 examples\n",
            "After 100 steps total reward = 14.670000000000018\n",
            "After 200 steps total reward = 34.508000000000045\n",
            "After 300 steps total reward = 44.20199999999983\n",
            "Currently there is 24893 examples\n",
            "After 100 steps total reward = 14.404000000000005\n",
            "Currently there is 25064 examples\n",
            "After 100 steps total reward = 12.344000000000003\n",
            "After 200 steps total reward = 27.95200000000006\n",
            "Currently there is 25290 examples\n",
            "After 100 steps total reward = 15.414000000000014\n",
            "After 200 steps total reward = 29.150000000000066\n",
            "Currently there is 25502 examples\n",
            "After 100 steps total reward = 17.43200000000002\n",
            "Currently there is 25612 examples\n",
            "After 100 steps total reward = 15.658000000000019\n",
            "After 200 steps total reward = 32.352000000000075\n",
            "Currently there is 25876 examples\n",
            "After 100 steps total reward = 14.422000000000018\n",
            "After 200 steps total reward = 28.206000000000078\n",
            "Currently there is 26083 examples\n",
            "After 100 steps total reward = 14.758000000000026\n",
            "After 200 steps total reward = 30.50800000000008\n",
            "Currently there is 26295 examples\n",
            "After 100 steps total reward = 15.574000000000023\n",
            "After 200 steps total reward = 30.400000000000084\n",
            "Currently there is 26574 examples\n",
            "After 100 steps total reward = 17.608000000000022\n",
            "Currently there is 26682 examples\n",
            "After 100 steps total reward = 18.612000000000027\n",
            "Currently there is 26839 examples\n",
            "After 100 steps total reward = 16.820000000000018\n",
            "Currently there is 27032 examples\n",
            "After 100 steps total reward = 13.60400000000001\n",
            "Currently there is 27199 examples\n",
            "After 100 steps total reward = 13.40800000000002\n",
            "Currently there is 27343 examples\n",
            "After 100 steps total reward = 13.682000000000022\n",
            "After 200 steps total reward = 28.378000000000075\n",
            "Currently there is 27603 examples\n",
            "After 100 steps total reward = 13.422000000000013\n",
            "After 200 steps total reward = 27.022000000000062\n",
            "Currently there is 27854 examples\n",
            "After 100 steps total reward = 18.426000000000023\n",
            "Currently there is 27958 examples\n",
            "After 100 steps total reward = 12.520000000000012\n",
            "After 200 steps total reward = 25.008000000000056\n",
            "Currently there is 28219 examples\n",
            "After 100 steps total reward = 16.600000000000016\n",
            "Currently there is 28362 examples\n",
            "After 100 steps total reward = 11.794000000000016\n",
            "Currently there is 28546 examples\n",
            "After 100 steps total reward = 15.64600000000002\n",
            "Currently there is 28739 examples\n",
            "After 100 steps total reward = 15.73000000000003\n",
            "Currently there is 28922 examples\n",
            "After 100 steps total reward = 14.584000000000021\n",
            "After 200 steps total reward = 30.16200000000007\n",
            "Currently there is 29188 examples\n",
            "After 100 steps total reward = 13.59800000000001\n",
            "Currently there is 29382 examples\n",
            "Currently there is 29478 examples\n",
            "After 100 steps total reward = 15.814000000000028\n",
            "After 200 steps total reward = 28.486000000000065\n",
            "Currently there is 29735 examples\n",
            "After 100 steps total reward = 14.45200000000001\n",
            "Currently there is 29898 examples\n",
            "After 100 steps total reward = 15.664000000000028\n",
            "After 200 steps total reward = 30.47200000000009\n",
            "Currently there is 30101 examples\n",
            "After 100 steps total reward = 14.642000000000017\n",
            "After 200 steps total reward = 29.502000000000077\n",
            "Currently there is 30311 examples\n",
            "After 100 steps total reward = 14.624000000000025\n",
            "Currently there is 30509 examples\n",
            "After 100 steps total reward = 15.150000000000013\n",
            "Currently there is 30690 examples\n",
            "After 100 steps total reward = 16.288000000000018\n",
            "After 200 steps total reward = 32.77400000000006\n",
            "Currently there is 30983 examples\n",
            "After 100 steps total reward = 13.710000000000013\n",
            "After 200 steps total reward = 32.27600000000006\n",
            "After 300 steps total reward = 44.12999999999982\n",
            "Currently there is 31350 examples\n",
            "After 100 steps total reward = 16.744000000000018\n",
            "After 200 steps total reward = 31.63200000000008\n",
            "Currently there is 31571 examples\n",
            "After 100 steps total reward = 14.502000000000026\n",
            "After 200 steps total reward = 29.208000000000087\n",
            "After 300 steps total reward = 42.03599999999991\n",
            "Currently there is 31938 examples\n",
            "After 100 steps total reward = 15.51400000000002\n",
            "After 200 steps total reward = 29.270000000000085\n",
            "Currently there is 32163 examples\n",
            "After 100 steps total reward = 16.638000000000027\n",
            "Currently there is 32303 examples\n",
            "After 100 steps total reward = 16.734000000000027\n",
            "After 200 steps total reward = 29.374000000000088\n",
            "After 300 steps total reward = 41.27399999999987\n",
            "Currently there is 32618 examples\n",
            "After 100 steps total reward = 19.420000000000016\n",
            "After 200 steps total reward = 32.17800000000007\n",
            "Currently there is 32888 examples\n",
            "Currently there is 32977 examples\n",
            "After 100 steps total reward = 12.372\n",
            "Currently there is 33096 examples\n",
            "After 100 steps total reward = 14.714000000000029\n",
            "Currently there is 33294 examples\n",
            "After 100 steps total reward = 16.506000000000025\n",
            "After 200 steps total reward = 31.192000000000085\n",
            "Currently there is 33504 examples\n",
            "After 100 steps total reward = 13.602000000000015\n",
            "Currently there is 33646 examples\n",
            "After 100 steps total reward = 12.360000000000015\n",
            "After 200 steps total reward = 26.208000000000066\n",
            "Currently there is 33926 examples\n",
            "After 100 steps total reward = 15.792000000000023\n",
            "After 200 steps total reward = 29.302000000000067\n",
            "After 300 steps total reward = 42.95199999999989\n",
            "After 400 steps total reward = 55.87399999999962\n",
            "Currently there is 34341 examples\n",
            "After 100 steps total reward = 15.84000000000003\n",
            "Currently there is 34527 examples\n",
            "After 100 steps total reward = 14.610000000000026\n",
            "After 200 steps total reward = 26.80800000000006\n",
            "After 300 steps total reward = 40.62599999999992\n",
            "After 400 steps total reward = 52.33599999999971\n",
            "After 500 steps total reward = 61.25599999999947\n",
            "Currently there is 35058 examples\n",
            "After 100 steps total reward = 16.55000000000002\n",
            "Currently there is 35195 examples\n",
            "After 100 steps total reward = 15.332000000000017\n",
            "After 200 steps total reward = 27.938000000000077\n",
            "Currently there is 35438 examples\n",
            "After 100 steps total reward = 13.67400000000001\n",
            "Currently there is 35580 examples\n",
            "After 100 steps total reward = 15.68400000000002\n",
            "After 200 steps total reward = 30.32400000000008\n",
            "After 300 steps total reward = 46.265999999999835\n",
            "Currently there is 35881 examples\n",
            "After 100 steps total reward = 14.536000000000016\n",
            "Currently there is 36059 examples\n",
            "After 100 steps total reward = 13.664000000000014\n",
            "After 200 steps total reward = 29.00000000000007\n",
            "After 300 steps total reward = 41.715999999999894\n",
            "Currently there is 36416 examples\n",
            "After 100 steps total reward = 14.514000000000019\n",
            "After 200 steps total reward = 31.226000000000077\n",
            "Currently there is 36712 examples\n",
            "After 100 steps total reward = 14.380000000000019\n",
            "After 200 steps total reward = 25.994000000000067\n",
            "Currently there is 36922 examples\n",
            "After 100 steps total reward = 13.384000000000015\n",
            "Currently there is 37079 examples\n",
            "After 100 steps total reward = 16.398000000000017\n",
            "After 200 steps total reward = 28.77200000000005\n",
            "Currently there is 37367 examples\n",
            "After 100 steps total reward = 12.44600000000001\n",
            "Currently there is 37554 examples\n",
            "After 100 steps total reward = 12.662000000000015\n",
            "After 200 steps total reward = 29.474000000000075\n",
            "After 300 steps total reward = 43.29599999999996\n",
            "Currently there is 37865 examples\n",
            "After 100 steps total reward = 16.83000000000002\n",
            "After 200 steps total reward = 32.32000000000004\n",
            "After 300 steps total reward = 47.21199999999979\n",
            "Currently there is 38233 examples\n",
            "After 100 steps total reward = 15.702000000000018\n",
            "After 200 steps total reward = 28.316000000000074\n",
            "Currently there is 38500 examples\n",
            "After 100 steps total reward = 18.704000000000025\n",
            "Currently there is 38690 examples\n",
            "After 100 steps total reward = 16.69600000000003\n",
            "After 200 steps total reward = 31.36200000000009\n",
            "After 300 steps total reward = 48.13799999999988\n",
            "Currently there is 39018 examples\n",
            "After 100 steps total reward = 14.58000000000002\n",
            "Currently there is 39182 examples\n",
            "After 100 steps total reward = 15.204000000000015\n",
            "After 200 steps total reward = 30.900000000000073\n",
            "Currently there is 39477 examples\n",
            "After 100 steps total reward = 14.278000000000013\n",
            "After 200 steps total reward = 32.726000000000035\n",
            "Currently there is 39715 examples\n",
            "After 100 steps total reward = 14.142000000000014\n",
            "After 200 steps total reward = 27.842000000000073\n",
            "After 300 steps total reward = 42.56799999999992\n",
            "After 400 steps total reward = 52.24599999999967\n",
            "Currently there is 40119 examples\n",
            "After 100 steps total reward = 15.340000000000023\n",
            "After 200 steps total reward = 27.052000000000078\n",
            "Currently there is 40366 examples\n",
            "After 100 steps total reward = 13.672000000000024\n",
            "After 200 steps total reward = 27.82000000000004\n",
            "Currently there is 40595 examples\n",
            "After 100 steps total reward = 16.484000000000023\n",
            "After 200 steps total reward = 31.29000000000008\n",
            "After 300 steps total reward = 44.215999999999845\n",
            "Currently there is 40994 examples\n",
            "After 100 steps total reward = 13.676000000000018\n",
            "Currently there is 41106 examples\n",
            "After 100 steps total reward = 15.684000000000026\n",
            "Currently there is 41233 examples\n",
            "After 100 steps total reward = 16.682000000000023\n",
            "Currently there is 41364 examples\n",
            "After 100 steps total reward = 17.44800000000003\n",
            "After 200 steps total reward = 35.22200000000005\n",
            "Currently there is 41576 examples\n",
            "After 100 steps total reward = 14.694000000000019\n",
            "Currently there is 41741 examples\n",
            "After 100 steps total reward = 18.666000000000032\n",
            "Currently there is 41904 examples\n",
            "After 100 steps total reward = 16.590000000000025\n",
            "After 200 steps total reward = 30.36600000000006\n",
            "Currently there is 42152 examples\n",
            "After 100 steps total reward = 14.42200000000001\n",
            "After 200 steps total reward = 30.098000000000066\n",
            "After 300 steps total reward = 45.02999999999987\n",
            "Currently there is 42506 examples\n",
            "After 100 steps total reward = 14.580000000000013\n",
            "After 200 steps total reward = 28.126000000000058\n",
            "Currently there is 42732 examples\n",
            "After 100 steps total reward = 12.528000000000011\n",
            "After 200 steps total reward = 28.282000000000068\n",
            "After 300 steps total reward = 40.2319999999999\n",
            "Currently there is 43032 examples\n",
            "After 100 steps total reward = 15.71800000000002\n",
            "After 200 steps total reward = 28.494000000000074\n",
            "After 300 steps total reward = 40.33799999999987\n",
            "Currently there is 43421 examples\n",
            "After 100 steps total reward = 16.65200000000003\n",
            "After 200 steps total reward = 28.336000000000087\n",
            "Currently there is 43670 examples\n",
            "After 100 steps total reward = 16.804000000000016\n",
            "Currently there is 43838 examples\n",
            "After 100 steps total reward = 12.86600000000001\n",
            "After 200 steps total reward = 27.452000000000062\n",
            "Currently there is 44124 examples\n",
            "After 100 steps total reward = 13.59000000000001\n",
            "Currently there is 44232 examples\n",
            "After 100 steps total reward = 14.768000000000018\n",
            "Currently there is 44418 examples\n",
            "After 100 steps total reward = 14.610000000000026\n",
            "After 200 steps total reward = 31.068000000000076\n",
            "Currently there is 44642 examples\n",
            "After 100 steps total reward = 16.63600000000001\n",
            "Currently there is 44782 examples\n",
            "After 100 steps total reward = 16.298000000000012\n",
            "After 200 steps total reward = 30.040000000000074\n",
            "Currently there is 44982 examples\n",
            "After 100 steps total reward = 16.78000000000002\n",
            "After 200 steps total reward = 32.48600000000006\n",
            "Currently there is 45193 examples\n",
            "Currently there is 45270 examples\n",
            "After 100 steps total reward = 15.488000000000008\n",
            "Currently there is 45467 examples\n",
            "Currently there is 45527 examples\n",
            "After 100 steps total reward = 11.598000000000013\n",
            "After 200 steps total reward = 26.430000000000074\n",
            "Currently there is 45747 examples\n",
            "After 100 steps total reward = 17.674000000000017\n",
            "Currently there is 45914 examples\n",
            "After 100 steps total reward = 13.410000000000002\n",
            "After 200 steps total reward = 25.692000000000036\n",
            "After 300 steps total reward = 41.46799999999987\n",
            "Currently there is 46230 examples\n",
            "After 100 steps total reward = 15.898000000000014\n",
            "After 200 steps total reward = 28.556000000000065\n",
            "Currently there is 46509 examples\n",
            "After 100 steps total reward = 16.634000000000018\n",
            "After 200 steps total reward = 32.35800000000006\n",
            "Currently there is 46733 examples\n",
            "After 100 steps total reward = 14.592000000000017\n",
            "After 200 steps total reward = 25.210000000000065\n",
            "After 300 steps total reward = 42.03399999999993\n",
            "Currently there is 47055 examples\n",
            "After 100 steps total reward = 15.368000000000013\n",
            "After 200 steps total reward = 25.972000000000065\n",
            "Currently there is 47317 examples\n",
            "After 100 steps total reward = 14.668000000000015\n",
            "After 200 steps total reward = 27.42400000000007\n",
            "Currently there is 47531 examples\n",
            "After 100 steps total reward = 14.410000000000009\n",
            "After 200 steps total reward = 28.030000000000065\n",
            "After 300 steps total reward = 38.66999999999996\n",
            "Currently there is 47866 examples\n",
            "After 100 steps total reward = 15.686000000000014\n",
            "After 200 steps total reward = 28.40200000000007\n",
            "Currently there is 48104 examples\n",
            "After 100 steps total reward = 17.782000000000025\n",
            "After 200 steps total reward = 34.693999999999974\n",
            "Currently there is 48326 examples\n",
            "After 100 steps total reward = 15.622000000000021\n",
            "After 200 steps total reward = 33.29200000000006\n",
            "Currently there is 48595 examples\n",
            "After 100 steps total reward = 18.782000000000032\n",
            "Currently there is 48701 examples\n",
            "After 100 steps total reward = 14.908000000000014\n",
            "After 200 steps total reward = 29.51200000000007\n",
            "Currently there is 48974 examples\n",
            "After 100 steps total reward = 15.814000000000023\n",
            "Currently there is 49093 examples\n",
            "After 100 steps total reward = 14.558000000000005\n",
            "After 200 steps total reward = 26.27200000000006\n",
            "After 300 steps total reward = 38.923999999999964\n",
            "After 400 steps total reward = 50.60999999999975\n",
            "Currently there is 49579 examples\n",
            "After 100 steps total reward = 13.624000000000013\n",
            "After 200 steps total reward = 28.386000000000077\n",
            "Currently there is 49825 examples\n",
            "After 100 steps total reward = 17.526000000000025\n",
            "After 200 steps total reward = 32.410000000000075\n",
            "After 300 steps total reward = 48.32599999999985\n",
            "Currently there is 50145 examples\n",
            "After 100 steps total reward = 15.65000000000002\n",
            "After 200 steps total reward = 32.31200000000007\n",
            "Currently there is 50393 examples\n",
            "After 100 steps total reward = 13.594000000000017\n",
            "Currently there is 50508 examples\n",
            "After 100 steps total reward = 13.21200000000002\n",
            "Currently there is 50697 examples\n",
            "After 100 steps total reward = 13.780000000000012\n",
            "Currently there is 50856 examples\n",
            "After 100 steps total reward = 14.728000000000025\n",
            "After 200 steps total reward = 29.448000000000082\n",
            "Currently there is 51110 examples\n",
            "After 100 steps total reward = 16.580000000000016\n",
            "Currently there is 51285 examples\n",
            "After 100 steps total reward = 15.622000000000021\n",
            "After 200 steps total reward = 31.236000000000086\n",
            "Currently there is 51548 examples\n",
            "After 100 steps total reward = 15.800000000000022\n",
            "Currently there is 51690 examples\n",
            "After 100 steps total reward = 14.730000000000024\n",
            "Currently there is 51874 examples\n",
            "After 100 steps total reward = 13.416000000000011\n",
            "After 200 steps total reward = 27.072000000000063\n",
            "Currently there is 52151 examples\n",
            "After 100 steps total reward = 15.41400000000002\n",
            "After 200 steps total reward = 28.908000000000072\n",
            "Currently there is 52351 examples\n",
            "After 100 steps total reward = 14.610000000000024\n",
            "After 200 steps total reward = 28.24600000000008\n",
            "Currently there is 52612 examples\n",
            "Currently there is 52691 examples\n",
            "After 100 steps total reward = 13.776000000000012\n",
            "After 200 steps total reward = 27.29200000000007\n",
            "Currently there is 52980 examples\n",
            "After 100 steps total reward = 13.568000000000007\n",
            "Currently there is 53087 examples\n",
            "After 100 steps total reward = 15.480000000000018\n",
            "After 200 steps total reward = 31.312000000000083\n",
            "Currently there is 53325 examples\n",
            "After 100 steps total reward = 14.426000000000025\n",
            "After 200 steps total reward = 29.87000000000008\n",
            "Currently there is 53572 examples\n",
            "After 100 steps total reward = 14.670000000000012\n",
            "After 200 steps total reward = 28.32800000000006\n",
            "After 300 steps total reward = 39.71999999999989\n",
            "Currently there is 53919 examples\n",
            "After 100 steps total reward = 14.706000000000024\n",
            "After 200 steps total reward = 28.280000000000076\n",
            "Currently there is 54144 examples\n",
            "After 100 steps total reward = 14.480000000000013\n",
            "After 200 steps total reward = 29.07200000000007\n",
            "Currently there is 54435 examples\n",
            "After 100 steps total reward = 16.62400000000002\n",
            "After 200 steps total reward = 29.922000000000068\n",
            "Currently there is 54657 examples\n",
            "After 100 steps total reward = 14.85000000000002\n",
            "After 200 steps total reward = 29.36200000000007\n",
            "Currently there is 54938 examples\n",
            "After 100 steps total reward = 13.582000000000017\n",
            "After 200 steps total reward = 26.048000000000066\n",
            "Currently there is 55195 examples\n",
            "After 100 steps total reward = 14.390000000000018\n",
            "After 200 steps total reward = 28.97400000000007\n",
            "Currently there is 55427 examples\n",
            "After 100 steps total reward = 13.522000000000014\n",
            "After 200 steps total reward = 30.92200000000005\n",
            "Currently there is 55634 examples\n",
            "After 100 steps total reward = 14.77400000000002\n",
            "After 200 steps total reward = 27.60200000000008\n",
            "Currently there is 55862 examples\n",
            "After 100 steps total reward = 14.220000000000022\n",
            "After 200 steps total reward = 28.95400000000009\n",
            "After 300 steps total reward = 41.75999999999992\n",
            "Currently there is 56173 examples\n",
            "After 100 steps total reward = 13.21600000000002\n",
            "After 200 steps total reward = 27.880000000000077\n",
            "Currently there is 56459 examples\n",
            "After 100 steps total reward = 15.446000000000017\n",
            "After 200 steps total reward = 35.21800000000002\n",
            "Currently there is 56710 examples\n",
            "After 100 steps total reward = 13.834000000000016\n",
            "Currently there is 56906 examples\n",
            "After 100 steps total reward = 13.590000000000003\n",
            "Currently there is 57064 examples\n",
            "After 100 steps total reward = 13.696000000000016\n",
            "After 200 steps total reward = 29.480000000000082\n",
            "Currently there is 57310 examples\n",
            "After 100 steps total reward = 14.244000000000007\n",
            "After 200 steps total reward = 29.864000000000065\n",
            "Currently there is 57534 examples\n",
            "After 100 steps total reward = 12.400000000000016\n",
            "After 200 steps total reward = 26.978000000000065\n",
            "After 300 steps total reward = 37.46399999999996\n",
            "Currently there is 57839 examples\n",
            "After 100 steps total reward = 14.476000000000013\n",
            "Currently there is 58034 examples\n",
            "After 100 steps total reward = 12.552000000000014\n",
            "After 200 steps total reward = 29.240000000000066\n",
            "Currently there is 58314 examples\n",
            "After 100 steps total reward = 11.49000000000001\n",
            "After 200 steps total reward = 26.042000000000076\n",
            "After 300 steps total reward = 40.85399999999992\n",
            "After 400 steps total reward = 50.80199999999965\n",
            "Currently there is 58783 examples\n",
            "After 100 steps total reward = 14.58600000000002\n",
            "After 200 steps total reward = 30.866000000000078\n",
            "Currently there is 59047 examples\n",
            "After 100 steps total reward = 15.548000000000023\n",
            "Currently there is 59236 examples\n",
            "After 100 steps total reward = 17.858000000000022\n",
            "After 200 steps total reward = 30.34800000000007\n",
            "Currently there is 59508 examples\n",
            "After 100 steps total reward = 16.54000000000002\n",
            "After 200 steps total reward = 29.350000000000094\n",
            "Currently there is 59785 examples\n",
            "After 100 steps total reward = 17.194000000000013\n",
            "After 200 steps total reward = 34.948000000000015\n",
            "After 300 steps total reward = 44.43799999999977\n",
            "Currently there is 60116 examples\n",
            "After 100 steps total reward = 17.45600000000002\n",
            "After 200 steps total reward = 30.886000000000067\n",
            "Currently there is 60369 examples\n",
            "After 100 steps total reward = 16.760000000000026\n",
            "After 200 steps total reward = 29.342000000000073\n",
            "Currently there is 60655 examples\n",
            "After 100 steps total reward = 17.670000000000023\n",
            "After 200 steps total reward = 35.40600000000001\n",
            "Currently there is 60888 examples\n",
            "After 100 steps total reward = 16.584000000000017\n",
            "Currently there is 61072 examples\n",
            "After 100 steps total reward = 12.322000000000005\n",
            "After 200 steps total reward = 25.69600000000003\n",
            "Currently there is 61288 examples\n",
            "After 100 steps total reward = 15.62800000000003\n",
            "After 200 steps total reward = 28.354000000000088\n",
            "After 300 steps total reward = 40.941999999999936\n",
            "After 400 steps total reward = 50.905999999999665\n",
            "After 500 steps total reward = 63.89599999999939\n",
            "Currently there is 61832 examples\n",
            "After 100 steps total reward = 16.798000000000023\n",
            "After 200 steps total reward = 29.474000000000085\n",
            "After 300 steps total reward = 43.02599999999995\n",
            "Currently there is 62215 examples\n",
            "After 100 steps total reward = 17.744000000000018\n",
            "After 200 steps total reward = 33.36400000000007\n",
            "After 300 steps total reward = 46.06399999999982\n",
            "Currently there is 62543 examples\n",
            "Currently there is 62630 examples\n",
            "Currently there is 62691 examples\n",
            "After 100 steps total reward = 14.536000000000028\n",
            "After 200 steps total reward = 30.004000000000065\n",
            "Currently there is 62956 examples\n",
            "After 100 steps total reward = 13.748000000000015\n",
            "Currently there is 63084 examples\n",
            "After 100 steps total reward = 14.532000000000025\n",
            "After 200 steps total reward = 31.218000000000085\n",
            "After 300 steps total reward = 44.02999999999987\n",
            "After 400 steps total reward = 57.90999999999961\n",
            "Currently there is 63499 examples\n",
            "After 100 steps total reward = 16.516000000000016\n",
            "After 200 steps total reward = 30.22000000000007\n",
            "After 300 steps total reward = 44.10399999999991\n",
            "Currently there is 63858 examples\n",
            "After 100 steps total reward = 17.796000000000024\n",
            "Currently there is 63997 examples\n",
            "After 100 steps total reward = 15.634000000000027\n",
            "Currently there is 64157 examples\n",
            "After 100 steps total reward = 14.284000000000022\n",
            "After 200 steps total reward = 27.598000000000077\n",
            "After 300 steps total reward = 41.30599999999989\n",
            "Currently there is 64478 examples\n",
            "After 100 steps total reward = 17.77400000000003\n",
            "Currently there is 64627 examples\n",
            "After 100 steps total reward = 13.69400000000002\n",
            "After 200 steps total reward = 26.49400000000008\n",
            "After 300 steps total reward = 40.247999999999955\n",
            "Currently there is 64970 examples\n",
            "After 100 steps total reward = 16.15200000000001\n",
            "After 200 steps total reward = 31.802000000000067\n",
            "Currently there is 65267 examples\n",
            "After 100 steps total reward = 14.430000000000021\n",
            "After 200 steps total reward = 30.294000000000082\n",
            "After 300 steps total reward = 46.15199999999986\n",
            "Currently there is 65586 examples\n"
          ]
        }
      ],
      "source": [
        "hewra = HeuristicAgent(game)\n",
        "initial_examples = hewra.generate_examples(2**16)  # bigger replay memory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NqOAiZ8bGnQ"
      },
      "source": [
        "#### Train agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poyTLSTuG92c",
        "outputId": "e89d1ebe-5d1e-43aa-8ae4-7bf2722f2837"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "128/128 [==============================] - 1s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 5s 11ms/step - loss: 0.0423\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0393\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.0441\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.0461\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0432\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0382\n",
            "##### Episode 1 reward = -0.16799999999999982 #####\n",
            "1/1 [==============================] - 0s 161ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0354\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0337\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.0299\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.0317\n",
            "##### Episode 2 reward = -0.43800000000000006 #####\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0743\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0975\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1335\n",
            "##### Episode 3 reward = -0.55 #####\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1929\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.0634\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.0413\n",
            "##### Episode 4 reward = -0.55 #####\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0449\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1084\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0913\n",
            "##### Episode 5 reward = -0.55 #####\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0354\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0310\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.0307\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0299\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0251\n",
            "##### Episode 6 reward = -0.04999999999999971 #####\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0313\n",
            "##### Episode 7 reward = -0.9 #####\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0357\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0352\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.0369\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "128/128 [==============================] - 1s 5ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0393\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0522\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0417\n",
            "##### Episode 8 reward = -0.09999999999999976 #####\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0405\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0578\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.0424\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0556\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0942\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0399\n",
            "##### Episode 9 reward = -0.07999999999999974 #####\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0358\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0349\n",
            "##### Episode 10 reward = -0.75 #####\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.0364\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0340\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0399\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0386\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0403\n",
            "##### Episode 11 reward = -0.2499999999999999 #####\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0360\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.0385\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0428\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.9612\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1958\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0605\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.0789\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0789\n",
            "##### Episode 12 reward = 0.24800000000000044 #####\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0599\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.0813\n",
            "##### Episode 13 reward = -0.75 #####\n",
            "1/1 [==============================] - 0s 97ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0677\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0673\n",
            "##### Episode 14 reward = -0.85 #####\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.0621\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0569\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0563\n",
            "##### Episode 15 reward = -0.7 #####\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0543\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0517\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0438\n",
            "##### Episode 16 reward = -0.6000000000000001 #####\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.0503\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0511\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0554\n",
            "##### Episode 17 reward = -0.55 #####\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0507\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0562\n",
            "##### Episode 18 reward = -0.75 #####\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0456\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.0473\n",
            "##### Episode 19 reward = -0.8 #####\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0547\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0591\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0534\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 1.0716\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0933\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0796\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.0644\n",
            "##### Episode 20 reward = -0.009999999999999676 #####\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0495\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0570\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0549\n",
            "##### Episode 21 reward = -0.6000000000000001 #####\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0544\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0491\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.0652\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0622\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0753\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0790\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0836\n",
            "##### Episode 22 reward = 1.2999999999999994 #####\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0701\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.0721\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.0870\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0653\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0922\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1152\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0875\n",
            "##### Episode 23 reward = 0.2000000000000004 #####\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.0699\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.0711\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0836\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0723\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0918\n",
            "##### Episode 24 reward = 0.8500000000000003 #####\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0825\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.0975\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.1053\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0733\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0782\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0703\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0737\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.0690\n",
            "##### Episode 25 reward = 0.3100000000000005 #####\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.0936\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0935\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0907\n",
            "##### Episode 26 reward = -0.5 #####\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1003\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0819\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.0742\n",
            "##### Episode 27 reward = -0.65 #####\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.0819\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0645\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0644\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0645\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0728\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0760\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.0733\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.0755\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0747\n",
            "##### Episode 28 reward = 0.5000000000000007 #####\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0883\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0718\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.2121\n",
            "##### Episode 29 reward = -0.45000000000000007 #####\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1940\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.1569\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1147\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1249\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0965\n",
            "##### Episode 30 reward = -0.09199999999999975 #####\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0921\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.0987\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1029\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0820\n",
            "##### Episode 31 reward = -0.44399999999999995 #####\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0866\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0913\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0821\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0807\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.1357\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0764\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0914\n",
            "##### Episode 32 reward = 0.0840000000000003 #####\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0680\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0708\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.0637\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.0593\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.0944\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0608\n",
            "##### Episode 33 reward = -0.029999999999999694 #####\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0669\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0570\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.0585\n",
            "##### Episode 34 reward = -0.6000000000000001 #####\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0695\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0640\n",
            "##### Episode 35 reward = -0.7 #####\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0568\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0806\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.0711\n",
            "##### Episode 36 reward = -0.45000000000000007 #####\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.0809\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0707\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0740\n",
            "##### Episode 37 reward = -0.6000000000000001 #####\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0758\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0902\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.1021\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.0961\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0915\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0994\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.0872\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1182\n",
            "##### Episode 38 reward = 0.38800000000000057 #####\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.1143\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 4.2206\n",
            "##### Episode 39 reward = -0.75 #####\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.8267\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.6300\n",
            "##### Episode 40 reward = -0.9 #####\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1654\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1338\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1316\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.1781\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1479\n",
            "##### Episode 41 reward = -0.2499999999999999 #####\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1460\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1356\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1533\n",
            "##### Episode 42 reward = -0.5 #####\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.1676\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.1370\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1675\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1584\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1175\n",
            "##### Episode 43 reward = -0.35 #####\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.1092\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.1119\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1378\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1277\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1019\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1017\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1180\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.1300\n",
            "##### Episode 44 reward = 0.4000000000000006 #####\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1388\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1299\n",
            "##### Episode 45 reward = -0.65 #####\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1192\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1266\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.1205\n",
            "##### Episode 46 reward = -0.55 #####\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.1809\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1577\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1895\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.2115\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1740\n",
            "##### Episode 47 reward = -0.2879999999999998 #####\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1850\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.1585\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1989\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.2104\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.2125\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.2413\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.1729\n",
            "##### Episode 48 reward = 0.26800000000000046 #####\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.2031\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1680\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.2004\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.2661\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.2134\n",
            "##### Episode 49 reward = -0.04999999999999971 #####\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.1818\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1499\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1274\n",
            "##### Episode 50 reward = -0.55 #####\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1877\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.2286\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1778\n",
            "##### Episode 51 reward = -0.6000000000000001 #####\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.1502\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1253\n",
            "##### Episode 52 reward = -0.85 #####\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1468\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1341\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1433\n",
            "##### Episode 53 reward = -0.6000000000000001 #####\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.1315\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.1124\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1407\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1180\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1399\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1496\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.1847\n",
            "##### Episode 54 reward = 0.2000000000000004 #####\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.1190\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1259\n",
            "##### Episode 55 reward = -0.8 #####\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.1043\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1063\n",
            "##### Episode 56 reward = -0.7 #####\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1292\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1410\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.1338\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1201\n",
            "##### Episode 57 reward = -0.2499999999999999 #####\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.2275\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.2021\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1798\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1459\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.1604\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1814\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.2732\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.3082\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.4348\n",
            "##### Episode 58 reward = 0.5200000000000007 #####\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.4371\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 4ms/step\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.4526\n",
            "##### Episode 59 reward = -0.65 #####\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.3196\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.2667\n",
            "##### Episode 60 reward = -0.7 #####\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.2113\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1948\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.2131\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.1501\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1712\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.1655\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.2092\n",
            "##### Episode 61 reward = 0.11000000000000032 #####\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1742\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.1198\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.3505\n",
            "##### Episode 62 reward = -0.45000000000000007 #####\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.4454\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.5717\n",
            "##### Episode 63 reward = -0.75 #####\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.4449\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.2702\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.2155\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.1872\n",
            "##### Episode 64 reward = -0.45000000000000007 #####\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1489\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1521\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1573\n",
            "##### Episode 65 reward = -0.6000000000000001 #####\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1373\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.1377\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1250\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1387\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1312\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1365\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.1405\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 13ms/step - loss: 0.1402\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.3359\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.2266\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1989\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1926\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.2290\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.2398\n",
            "##### Episode 66 reward = 1.2320000000000002 #####\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.2404\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.4117\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.6659\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.3533\n",
            "##### Episode 67 reward = -0.392 #####\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.4742\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.3983\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.2507\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "128/128 [==============================] - 1s 4ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.2225\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.4199\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.2309\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.2174\n",
            "##### Episode 68 reward = 0.11000000000000032 #####\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.1624\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1694\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.2054\n",
            "##### Episode 69 reward = -0.45000000000000007 #####\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.2471\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.1542\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.1656\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.3191\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.2238\n",
            "##### Episode 70 reward = -0.04999999999999971 #####\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.2022\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.2463\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.2797\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 4ms/step\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.3160\n",
            "##### Episode 71 reward = 0.6560000000000006 #####\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 1.4654\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.8191\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 1.4746\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.6094\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.4047\n",
            "##### Episode 72 reward = -0.2499999999999999 #####\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.3156\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.2605\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.3554\n",
            "##### Episode 73 reward = -0.55 #####\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.3435\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.4087\n",
            "##### Episode 74 reward = -0.8 #####\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.6048\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.5311\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.4412\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.2909\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.3675\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.4068\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.7022\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.3426\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.6856\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.7829\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.1833\n",
            "##### Episode 75 reward = 0.816000000000001 #####\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 1.1313\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.1888\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 2.3655\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 1.4703\n",
            "##### Episode 76 reward = -0.35 #####\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.5139\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.8963\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.1416\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 1.7538\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.7866\n",
            "##### Episode 77 reward = -0.29999999999999993 #####\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 1.3212\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 1.0412\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 1.2234\n",
            "##### Episode 78 reward = -0.6000000000000001 #####\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 1.1060\n",
            "##### Episode 79 reward = -0.9 #####\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 4ms/step\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.9768\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 1.6361\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 1.3766\n",
            "##### Episode 80 reward = 0.4500000000000002 #####\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.6616\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 1.3908\n",
            "##### Episode 81 reward = -0.65 #####\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.6844\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.7674\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 166ms/step\n",
            "128/128 [==============================] - 1s 5ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 1.1387\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 2.0130\n",
            "##### Episode 82 reward = -0.35 #####\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 2.4854\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 2.6196\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.6818\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 3.0204\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.6570\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 1.7063\n",
            "##### Episode 83 reward = 0.0840000000000003 #####\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.5133\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 1.4231\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 1.3243\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.7124\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 2.4494\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 3.5892\n",
            "##### Episode 84 reward = 2.220446049250313e-16 #####\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 4ms/step\n",
            "64/64 [==============================] - 1s 14ms/step - loss: 3.4082\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 3.6768\n",
            "##### Episode 85 reward = 0.2500000000000002 #####\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 7.4750\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 3.9126\n",
            "##### Episode 86 reward = -0.8 #####\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 4.7047\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 3.9120\n",
            "##### Episode 87 reward = -0.9 #####\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 3.3684\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 5.1381\n",
            "128/128 [==============================] - 1s 5ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 11.2553\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 13.5667\n",
            "##### Episode 88 reward = -0.4 #####\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 11.9726\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.9062\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 21.6715\n",
            "##### Episode 89 reward = -0.5940000000000001 #####\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 13.7302\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 39.5914\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 161.4957\n",
            "##### Episode 90 reward = -0.6000000000000001 #####\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 13.2830\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 13.1301\n",
            "128/128 [==============================] - 0s 3ms/step\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 1.0762\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "128/128 [==============================] - 1s 4ms/step\n",
            "128/128 [==============================] - 1s 6ms/step\n",
            "64/64 [==============================] - 2s 29ms/step - loss: 27.6121\n",
            "1/1 [==============================] - 0s 185ms/step\n"
          ]
        }
      ],
      "source": [
        "agent = DqnAgent(game)\n",
        "agent.train(\n",
        "    500,\n",
        "    min_epsilon=0.1,\n",
        "    max_epsilon=1,\n",
        "    decay=0.3,  # TODO: try linear decay\n",
        "    learning_rate=0.0001,\n",
        "    epochs=1,\n",
        "    min_steps_to_update_target_model=20,\n",
        "    discount_factor=0.99,\n",
        "    batch_size=2**12,\n",
        "    initial_examples=initial_examples,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWaqyKjqRuo1"
      },
      "source": [
        "lower lr, vary steps to update target model (too low -> model chases a changing reward, too high -> takes too long to learn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqHD12n6bKFm"
      },
      "source": [
        "#### Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "yg-FLCDwaXCh",
        "outputId": "e47a4b8f-a29d-4aa7-dd32-00dfc0f11ece"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "agent.plot_rewards()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MmE_QWI4TSP"
      },
      "outputs": [],
      "source": [
        "agent.play_game()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUmyYU6o_fOM"
      },
      "outputs": [],
      "source": [
        "agent.play_game()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXAt6VnqUBI2"
      },
      "outputs": [],
      "source": [
        "agent.play_game()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zWdaY9pUBg1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Xb3fI2c9QMow",
        "78liGLuQQKFN",
        "jSSIgww1P_-w"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (mpdw)",
      "language": "python",
      "name": "mpdw"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}